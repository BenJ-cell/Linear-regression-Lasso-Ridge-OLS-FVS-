# Linear-regression-Lasso-Ridge-OLS-FVS-
In order to predict new values for an unseen point x, we use the normal equations which are based upon the model that the output and the input are linearly linked. Moreover if the Graam Matrix is invertible we get a closed form solution for the estimator Teta (Ridge,Lasso,PCA) using either Fermat's first rule looking to set the gradient to zero or simply using the invertibility of the Graam matrix. Therefore choosing for example a linear model with a gaussian error we may deduce a confidence interval for our data. If there is no randomness involved by a linear interpolation we can deduce an exact value for the y corresponding to our new x. PCA before OLS/ OLS on selected variables
